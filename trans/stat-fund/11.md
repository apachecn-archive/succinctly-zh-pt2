**Alpha 级别(** **α** **):** 也称为显著性级别，Alpha 级别定义了您认为某个值或样本不太可能出现的概率。它等于临界区域的面积。如果 p < α，你拒绝零假设，并得出结论，你的结果是有意义的。

**替代假设(H <sub class="calibre24">a</sub> ):** 替代假设指出结果是显著的(在 z 检验或 t 检验的情况下，它指出两个特定值或样本之间存在显著差异)。

**方差分析(ANOVA):** 我们使用 ANOVA 来测试三个或更多样本的任何一对(连续的)是否由于自变量(分类的)的不同值而彼此显著不同。双向方差分析还告诉我们在分析中使用的两个因素之间是否存在交互作用。

**箱线图:**箱线图通过显示最小值、最大值、Q <sub class="calibre24">1</sub> 、Q <sub class="calibre24">2</sub> (中间值)、Q <sub class="calibre24">3</sub> 以及任何异常值的位置来可视化数据的传播。

**中心极限定理:**这个定理说明，对于任意分布形状的种群，抽样分布(大小为 n 的所有可能样本的均值分布)将是正态的，均值μ和标准差∑ / √n。

**中心趋势:**这是一个描述一组数字聚集的术语。可以使用平均值、中值或模式进行测量。

**卡方统计量(****c****T5【2】****):**用于卡方检验，其中![](../images/00178.jpeg)其中*f<sub class="calibre24">0</sub>T14】为观察值，*f<sub class="calibre24">E</sub>T18】为期望值。**

**卡方检验:**该检验用于表列分类数据，并告诉我们观察值(即受试者属于每个类别的频率)是否与期望值有显著差异。

**置信区间:**置信区间是数值的 C%所在的数值范围。我们可以通过知道落在总体平均值μ的一定数量的标准偏差(z*)内的值或样本平均值的百分比来计算置信区间。

**相关系数(r):** 相关系数是描述两个变量之间关系的强度和方向的单一统计量，其中 r 的范围为-1(完美的负关系)和 1(完美的正关系)—值越接近 0 表示关系越弱。

**协方差(cov <sub class="calibre24">x，y</sub> ):** 协方差通过从 x 和 y 值各自的平均值中找出它们的平均乘积来衡量 x 的变化与 y 的变化之间的关联。

![](../images/00179.jpeg)

**临界区域:**这是一个分布上的区域，其中某个值或样本被认为非常不可能。如果样本统计量比临界值(标志着临界区域的截止点)更靠近分布的尾部，则结果是显著的。在关键区域着陆的概率等于**α**T4。

**数据:**数据是我们用来得出所有统计结论的东西。在进行任何分析之前，我们必须首先了解数据的类型(例如，分类与数字、离散与连续)，将其可视化(例如，通过绘制直方图)，并对其进行描述(至少，找到最小、最大、平均、中值和标准偏差)。

**自由度(df):** 这些是给定指定参数下可以改变的值的数量。例如，如果平均值已知，则前 n-1 个值可以是任何值，但最后一个值必须保证平均值保持指定值。因此，在这个例子中，n-1 是自由度。

**因变量:**这个变量通常被认为受自变量的影响(虽然这本电子书中的测试是为了关联而不是因果关系)。

**偏差:**这是特定值和期望值(通常是平均值)之间的差值。

**分布:**分布是在特定范围或区间中绘制数据集中值的频率时创建的形状。常见的分布包括正态分布、均匀分布、偏斜分布和双峰分布。

**期望值:**这些是我们基于一个或多个因素期望获得的值。在一个样本的情况下，如果我们随机选择一个特定的值，期望值就是平均值。在回归中，y(因变量)的期望值基于 x(自变量)的值。

**F-临界值(F** **<sub class="calibre24">α</sub>** **<sub class="calibre24">，k-1，N-k</sub>** **):** 这是方差分析中使用的临界区域的截止值。这里，k - 1 是组间可变性的自由度(少一个样本数，k)，而 N - k 是组内可变性的自由度(k 少于值的总数，N)。

**频率:**这是特定类别或范围内的数值数量。

**直方图:**直方图将值在有序的数字仓中的出现频率可视化，这样我们就可以很容易地看到数据是如何分布的。

**假设检验:**这个程序用于许多统计检验，以确定一个值、样本、比例等是否成立。，明显不同于预期。它包括陈述无效假设和替代假设，并将一个统计量(观察值和期望值之间差异的度量)与一个临界值进行比较，以确定该统计量是否显著较大。如果统计值大于临界值，则认为结果是重要的。

**自变量:**这个变量通常被认为会影响因变量(虽然这本电子书中的测试是为了关联而不是因果关系)。

**四分位数区间(IQR):** 这是一种通过找出第三个四分位数和第一个四分位数之间的差异来忽略极值的价差度量(Q<sub class="calibre24">3</sub>–Q<sub class="calibre24">1</sub>)。方框图中的矩形显示了 IQR。

**平均值:**平均值是一种中心度量，在计算中会考虑到数据集中的每个值。算术平均值将样本或总体中的所有值相加，并(分别)除以样本大小(N)或总体大小(N)。

**中枢的度量:**这是中枢倾向的度量。三种最常见的中心度量是平均值、中位数和众数。每个都有助于以自己的方式理解数据集；一种方法并不总是比另一种方法更准确。

**传播的度量:**这是可变性的度量。范围(最大值和最小值之间的差值)是最简单的传播度量之一。其他度量包括 IQR、方差、平均绝对偏差和更常用的标准偏差。

**中值:**中值是代表第 50 个<sup class="calibre57">百分位的中心度量，即数据集中一半值小于中值，一半值大于中值。对于奇数数据集，中位数是中间值，对于偶数数据集，中位数是两个中间值的平均值。</sup>

**模式:**模式是表示具有最大频率的值(在离散数据的情况下)、值的范围(在大数据集或连续数据的情况下)或类别(在分类数据的情况下)的中心的度量。

**零假设(H <sub class="calibre24">0</sub> ):** 在假设检验中，零假设代表结果不显著的结果。

**观察值:**这些是样品中发现的实际值。观测值通常不遵循完美的模式，这意味着我们需要测量误差或可变性。

**异常值:**这些是数据集中与其他值显著不同的值；具体来说，它们低于 Q<sub class="calibre24">1</sub>1.5 IQRs 或高于 Q<sub class="calibre24">3</sub>1.5 IQRs。

**种群:**种群由每个人或所有具有所研究特征的事物组成，而不是它们的子集。

**事后测试:**这是在方差分析后进行的测试，目的是确定哪两组有显著差异。当方差大致相等时，可以使用 Tukey 的 HSD 游戏豪威尔测试可以在没有的时候使用。莱文的方差齐性检验帮助我们决定执行哪种检验。

**概率密度函数(PDF):** 该曲线对数据集的分布进行建模。PDF 下的面积等于累积概率(因此，PDF 下的总面积为 1)。

**范围:**范围是等于最大值减去最小值的价差度量。

**回归:**这个统计过程包括对因变量和一个或多个自变量之间的趋势进行建模，允许您根据每个自变量的指定值计算因变量的期望值。

**回归线:**在线性回归中，回归线(ŷ= b<sub class="calibre24">0</sub>+b<sub class="calibre24">1</sub>x<sub class="calibre24">1</sub>+b<sub class="calibre24">2</sub>x<sub class="calibre24">2</sub>+…+b<sub class="calibre24">n</sub>x<sub class="calibre24">n</sub>是根据观察到的 x 值输出预期 y 值(ŷ)的方程。它也被称为最佳拟合线，因为它最小化了残差平方和σ(y<sub class="calibre24">I</sub>–ŷ<sub class="calibre24">I</sub>)<sup class="calibre57">2</sup>。

**残差:**在回归中，残差是给定的观测 x 值(x <sub class="calibre24">i</sub> )等于 y<sub class="calibre24">I</sub>–ŷ<sub class="calibre24">I</sub>的观测值(y <sub class="calibre24">i</sub> )和期望值(ŷ <sub class="calibre24">i</sub> 之间的差值。

**样本:**样本是群体的子集。对于稳健的统计分析，应随机选择样本。

**样本标准偏差:**当使用样本估计总体标准偏差时，我们将方差之和除以 n-1(而不是 n)，以校正样本与总体相比可能较小的标准偏差。

![](../images/00180.jpeg)

**抽样分布:**这是可以从一个总体中获取的所有 n 大小样本的样本均值分布。均值等于总体均值(μ)，标准差等于总体标准差除以样本量的平方根(≘√)。

**标准偏差(** **∑** **):** 这是统计分析中最常用的价差度量。它等于平均平方偏差的平方根(方差的平方根)。

![](../images/00181.jpeg)

**标准误差(SE):** 这是一种误差的度量，通常等于感兴趣分布的标准偏差，它是计算统计量(如 z、t、F)时用于确定显著性的分母。对于 z 分数，错误为**∑**；对于采样分布，误差为∞/√n。

**标准正态分布:**标准正态分布，表示为 N(0，1)，均值为 0，标准差为 1。z 表给出了任何 z 分数在标准正态曲线下的累积概率。

**标准化:**这是为了计算概率，将正态分布转换为标准正态曲线的过程。

**平方和(SS):** 这是与平均值的平方偏差之和，例如![](../images/00182.jpeg)。

**t-临界值(t****<sub class="calibre24">α</sub>**<sub class="calibre24">df</sub>**):**t-临界值是 t-检验结果显著的临界值。它基于选定的α水平。

**t-分布:**当我们不知道总体标准差( **∑** )而用样本标准差来近似时，我们的结果容易出错。因此，我们使用 t 分布代替 z 分布。自由度越少，为了解释误差的增加，t 分布的尾部越粗。随着自由度的增加，t 分布更接近正态分布。

**t-统计量(t):**t-统计量是一种将两个值之间的差异与误差量进行比较的度量。如果差值足够大或误差足够小(即 t 统计量落在 t 分布的尾部比 t 临界值更远)，我们拒绝零。

**t 检验:**当我们不知道总体参数时，我们执行 t 检验来确定显著性，我们希望确定来自相对正态分布的特定值是否显著，或者两个样本之间的差异是否显著。

**可变性:**这是一个描述数据集中误差的术语。方差和标准差都是可变性的度量。

**方差(****∑****<sup class="calibre57">2</sup>****):**方差是变异性的度量，等于平均平方偏差(即平方和除以样本量)。

![](../images/00183.jpeg)

**z-临界值(z *):**z-临界值定义由所选 a 级定义的临界区域的截止值。如果 z 分数落在分布尾部的距离比 z*更远，则结果是显著的，我们拒绝零假设。

**z 分数(z):**z 分数表示一个值与平均值的标准偏差数。通过知道 z 分数，我们可以使用 z 表找到累积概率。

**z 检验:**当我们知道总体参数μ和∑时，我们对显著性进行 z 检验。我们可以使用 z 检验来确定某个特定值或比例是否显著偏离总体平均值。