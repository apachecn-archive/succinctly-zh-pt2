# 第三章单变量统计

在第二章中，我们研究了一个变量的图，这是分析的最佳开始步骤。在第三章中，我们将检查图形分析的后续工作:一个变量的统计过程。

## 频率

和上一章一样，我们将从分类变量开始。分类变量最常见的统计数据是频率和比例。我们将首先基于最近的谷歌搜索创建一个数据集。

**样本:样本 _3_1。R**

```r
          # ENTER DATA
          # Hits in millions for each word on Google
          groups <- c(rep("blue", 3990),
                      rep("red", 4140),
                      rep("orange", 1890),
                      rep("green", 3770),
                      rep("purple", 855))

```

`rep()`功能重复一个项目指定的次数。例如，在上面的代码中，它将单词“blue”重复了 3990 次。当五个颜色词放在对象`groups`中时，有 14645 行数据。虽然以表格的形式处理数据可能更容易——这是我们将要做的——但我更喜欢每个案例都有一行的数据集。

下一个命令创建一个数据表:

```r
          # CREATE FREQUENCY TABLES
          groups.t1 <- table(groups)  # Creates frequency table
          groups.t1  # Print table
            blue  green orange purple    red
            3990   3770   1890    855   4140

```

数据现在是按字母顺序排列的。有时这可能会有所帮助，但目前来看，按频率排序更有意义。

```r
          # MODIFY FREQUENCY TABLES
          groups.t2 <- sort(groups.t1, decreasing = TRUE)  # Sorts by frequency
          groups.t2  # Prints table
          groups
             red   blue  green orange purple
            4140   3990   3770   1890    855

```

您可能还想以比例或百分比而不是频率来表示数据。功能`prop.table()`会这样做:

```r
          # PROPORTIONS AND PERCENTAGES
          prop.table(groups.t2)  # Gives proportions of the total.
                red      blue     green    orange    purple
          0.2826903 0.2724479 0.2574257 0.1290543 0.0583817

```

这张表的小数位数太多了。我们可以通过`round()`功能解决这个问题。我们将`prop.table()`函数放入其中，并指定我们想要的小数位数:

```r
          round(prop.table(groups.t2), 2)  # Round to 2 decimal places.
             red   blue  green orange purple
            0.28   0.27   0.26   0.13   0.06

```

这是一个进步，但我们可以更进一步。前导零和小数是重复的。我们可以通过将结果乘以 100 来删除它们:

```r
          round(prop.table(groups.t2), 2) * 100  # Percents without decimals.
             red   blue  green orange purple
              28     27     26     13      6

```

保存工作后，应使用`rm(list = ls())`清除工作空间中不需要的变量和对象。

## 描述性统计

对于分类变量，有用的描述性统计数据数量有限。然而，对于数量变量，有更广泛的选择。在本节中，我们将使用 R 的内置函数和来自外部包的函数。它们共同为我们的数据提供了丰富的统计图片。

我们将使用 R 的数据集`cars`，它给出了以 MPH 为单位的汽车速度和以英尺为单位的停车距离。这些数据是在 20 世纪 20 年代记录的，所以有一些不寻常的值，比如一辆汽车以 120 英尺的速度从 24 英里/小时停下来。(详见`?cars`。)

**样品:样品 _3_2。R**

```r
          # LOAD DATA SET
          require(“datasets”)  # Load the data sets package
          cars  # Print the cars data to the console
          data(cars)  # Load the data into the workspace

```

在 R 中获取描述性统计最简单的方法是使用`summary()`函数。对于定量变量，该函数给出了五个四分位数的值——最小值、第一个四分位数、中值、第三个四分位数和最大值——以及平均值。也可以给出一些分类统计。

要获取单个变量的统计信息，请输入变量的名称:

```r
          summary(cars$speed)  # Summary for one variable
             Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
              4.0    12.0    15.0    15.4    19.0    25.0 

```

您也可以一次完成整个数据集:

```r
          summary(cars)  # Summary for entire table (inc. categories)
               speed           dist      
           Min.   : 4.0   Min.   :  2.00 
           1st Qu.:12.0   1st Qu.: 26.00 
           Median :15.0   Median : 36.00 
           Mean   :15.4   Mean   : 42.98 
           3rd Qu.:19.0   3rd Qu.: 56.00 
           Max.   :25.0   Max.   :120.00     

```

描述性统计的另一个选项是`psych`包中的`describe`功能。这提供了以下内容:

*   n
*   意思是
*   标准偏差
*   中位数
*   修剪平均值(默认为 10%)
*   中位数绝对偏差中位数
*   最低限度
*   最高的
*   范围
*   歪斜
*   峭度
*   标准误差

要使用 description 函数，必须先安装并加载`psych`包，然后调用`describe()`函数:

```r
          # ALTERNATIVE DESCRIPTIVES
          require("psych")
          describe(cars)   
                var  n  mean    sd median trimmed   mad
          speed   1 50 15.40  5.29     15   15.47  5.93
          dist    2 50 42.98 25.77     36   40.88 23.72
                  min  max range  skew kurtosis   se
          speed     4   25    21 -0.11    -0.67 0.75
          dist      2  120   118  0.76     0.12 3.64      

```

有关该套餐的更多信息，请输入`help(package = "psych")`。有关`describe()`功能的帮助，请输入`?describe`。

保存工作后，您应该清除工作区中不需要的变量、对象或包:

```r
          # CLEAN UP
          detach("package:datasets", unload = TRUE)  # Unloads data sets package.
          detach("package:psych", unload=TRUE)  # Unloads psych package.
          rm(list = ls())  # Remove all objects from workspace.

```

## 单一比例:假设检验和置信区间

最简单的推理程序是针对单一比例的。这些是二分法的结果:通过或失败，是或否，左或右，等等。这些程序唯一需要的数据是试验次数 n 和阳性结果数 X。例如，如果一个人掷硬币 40 次，得到 27 个头，那么 n = 40，X = 27。r 的`prop.test()`函数能够对这些比例进行零假设检验和置信区间检验。在这个例子中，我们将使用我们的硬币翻转数据，首先是默认设置，然后是一些选项。

**样品:样品 _3_3。R**

```r
          # PROPORTIONS TEST WITH DEFAULTS
          prop.test(27, 40)  # 27 heads in 40 coin flips.
                  1-sample proportions test with continuity correction
          data:  27 out of 40, null probability 0.5
          X-squared = 4.225, df = 1, p-value = 0.03983
          alternative hypothesis: true p is not equal to 0.5
          95 percent confidence interval:
           0.5075690 0.8092551
          sample estimates:
              p
          0.675

```

在这些结果中，R 重复数据——40 个试验中有 27 个阳性结果——并给出 0.5 的默认零概率。“X 平方”为 c <sup>2</sup> ，卡方值为 4.225。在一个自由度下，我们观察到的结果的概率值为 0.03983。因为这个值小于标准. 05，我们拒绝零假设；也就是说，我们得出结论，40 个头部中有 27 个在统计上显著大于 50%。然后 r 陈述了另一个假设，即真实的 p，或积极结果的概率，不等于 0.5。接下来是该比例的 95%置信区间，范围从 0.51 到 0.81。输出结束时，观察到的样本比例为 0.675，即 67.5%。

r 还为单样本比例测试提供了几个选项。这些选项包括:

*   0.5 以外的空比例的选择。非方向性、双侧假设检验或方向性、单侧检验。在后一种情况下，您必须指定是否假设样本比例大于或小于总体值。
*   选择不同于默认值 0.95 的置信水平。
*   是否使用耶茨连续性校正的选择；默认值是使用它。

使用这些选项中的一些，我们可以修改之前进行的假设检验，以检验样本比例是否明显大于 0.6 的人口比例，我们可以使用 0.90 的置信水平:

```r
          # PROPORTION TEST WITH OPTIONS
          prop.test(27, 40,  # Same observed values.
                    p = .6,  # Null probability of .6 (vs. .5).
                    alt = "greater",  # Directional test for greater value.
                    conf.level = .90)  # Confidence level of 90% (vs. 95%).

                  1-sample proportions test with continuity correction
          data:  27 out of 40, null probability 0.6
          X-squared = 0.651, df = 1, p-value = 0.2099
          alternative hypothesis: true p is greater than 0.6
          90 percent confidence interval:
           0.5619655 1.0000000
          sample estimates:
              p
          0.675

```

虽然 67.5%的样本比例与默认测试相同，但我们现在使用的是 60%的总体。即使有方向假设，样本值与空值也没有显著差异；p 值为 0.21 时，我们不能拒绝零假设。置信区间也很有趣，因为它是有方向性的。结果，上限变为 1.000，这对于标准的非定向测试来说是做不到的。

保存工作后，应使用`rm(list = ls())`清除工作空间中不需要的变量和对象。

## 单均值:假设检验和置信区间

对于定量变量，即测量区间或比率水平的变量，最简单的测试是单样本 t 检验。该测试将样本平均值与假设的总体平均值进行比较。

在这个例子中，我们将使用 R 的`quakes`数据集。这个数据集包括地震的位置、深度和震级，以及探测到地震的测量站的数量。它包括斐济沿海 1000 次地震的数据，震级至少为里氏 4.0 级。

我们将检查一个变量:`mag`，以了解大小。然而，在我们进行 t 检验之前，我们至少应该得到一个直方图和一些基本的汇总统计数据。

**样品:样品 _3_4。R**

```r
          # LOAD DATA & EXAMINE
          require(“datasets”)  # Loads data sets package.
           mag <- quakes$mag  # Loads just the magnitude variable.
          hist(mag)
          summary(mag)

```

图 20 中的直方图显示该分布具有很强的正偏斜。该分布受到审查，没有低于 4.0 的值，因此很难知道整个分布的形状。

![Mac:Users:bart:Documents:Dropbox:_Projects:_R:R Succinctly:Images:Figure_20_HistMag.png](img/image020.png)

图 20:地震震级直方图

`mag`的基本汇总统计有:

```r
             Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
             4.00    4.30    4.60    4.62    4.90    6.40

```

这里重要的值是 4.62 的平均值，因为这是 t 检验与假设的总体平均值进行比较的值。

默认的 t-test 运行起来很简单:

```r
          # T-TEST WITH DEFAULTS
          t.test(mag)
                  One Sample t-test
          data:  mag
          t = 362.7599, df = 999, p-value < 2.2e-16
          alternative hypothesis: true mean is not equal to 0
          95 percent confidence interval:
           4.595406 4.645394
          sample estimates:
          mean of x
             4.6204

```

输出类似卡方检验。它给出的 t 值是 362.7599，这是巨大的。自由度为 999，概率值几乎为零:2.2e-16。然而，这些强有力的结果并不令人惊讶；假设的总体平均值为 0，但数据中的最低值为 4。输出还包括 95%置信区间的界限和观察到的样本平均值。

和卡方检验一样，t 检验也提供了几种选择。(详见`?t.test`。)下面的 t 检验使用了其中的一些选项:

```r
          # T-TEST WITH OPTIONS
          t.test(mag,
                 alternative = "greater",  # Directional test
                 mu = 4.5,                 # Null population mean of 4.5
                 conf.level = 0.99)        # Confidence level of 99%

                  One Sample t-test
          data:  mag
          t = 9.4529, df = 999, p-value < 2.2e-16
          alternative hypothesis: true mean is greater than 4.5
          99 percent confidence interval:
           4.590722      Inf
          sample estimates:
          mean of x
             4.6204

```

这里的结论与默认的 t 检验相匹配:p 值几乎为零，我们拒绝零假设。即使我们选择了 4.5 的假设总体平均值(m 或μ)，这也是正确的，这更接近样本平均值 4.62。这两种方法之间的差异比以前小得多，但是，考虑到 1000 的大样本量，即使是可以忽略的差异在统计上也是显著的。

保存工作后，您应该清除工作区中不需要的变量、对象或包:

```r
          # CLEAN UP
          detach("package:datasets", unload = TRUE)  # Unloads data sets package.
          rm(list = ls())  # Remove all objects from workspace.

```

## 卡方拟合优度检验

当一个分类变量包含两个以上的类别时，卡方-c<sup>2</sup>测试可能会有用。在本书的这一部分，我们将讨论卡方检验的一种变体:拟合优度检验。该测试将您的样本在每个类别中的比例与假设的比例进行比较。您可以检查每个类别中是否有相同数量的观察结果。(详见`?chisq.test`。)这是我们将首先介绍的测试版本。您还可以检查您的观察结果是否与其他假设的分布相匹配。之后我们会报道的。

R 中的卡方检验使用汇总表作为输入。如果每个案例都有一行数据，或者有多维表，则可能需要重新构建数据。在这个例子中，我们将使用来自 R 的`datasets`包的三维表格`HairEyeColor`。

**样本:样本 _3_5。R**

```r
          # LOAD DATA & EXAMINE
          require(“datasets”)  # Loads data sets package.
          # SHOW DATA & MARGINAL FREQUENCIES
          HairEyeColor  # Shows data; see ?HairEyeColor for more information.
          margin.table(HairEyeColor, 1)  # Hair color marginal frequencies.
          margin.table(HairEyeColor, 2)  # Eye color marginal frequencies.
          margin.table(HairEyeColor, 3)  # Sex marginal frequencies.
          margin.table(HairEyeColor)     # Total frequencies.

```

输入`?HairEyeColor`，可以看到满满的三向桌。然而，在这个分析中，我们只看眼睛的颜色，所以我们应该创建一个新的数据框来保存这些数据。

```r
          # CREATE DATA FRAME
          eyes <- margin.table(HairEyeColor, 2)  # Save the table.
          eyes  # Show frequency table in the console.
          Brown  Blue Hazel Green
            220   215    93    64

          round(prop.table(eyes), 2)  # Proportions w/2 digits
          Brown  Blue Hazel Green
           0.37  0.36  0.16  0.11

```

我们将首先进行卡方拟合优度测试，假设眼睛颜色均匀分布。这是`chisq.test()`的默认设置。

```r
          # CHI-SQUARED GOODNESS-OF-FIT 1
          # DEFAULT: EQUAL FREQUENCIES
          chi1 <- chisq.test(eyes)  # Save test as object "chi1"
          chi1  # Check results.
                  Chi-squared test for given probabilities
          data:  eyes
          X-squared = 133.473, df = 3, p-value < 2.2e-16

```

卡方检验统计量，在 R 的打印输出中显示为 X 平方，是巨大的:133.473。三个自由度，测试结果概率值接近于零。因为这个概率值小于 0.06 的传统截止值，实际上要小得多，所以我们拒绝四种眼睛颜色在我们的样本中同样常见的零假设。

然而，这不是最合适的测试。眼睛颜色分布不均匀。一个更好的测试是我们的样本比例是否与眼睛颜色的总体比例有显著差异。r 没有提供这方面的人口数据，但互联网提供了。一个网站[【9】](11.html#_ftn9)建议棕色、蓝色、淡褐色和绿色眼睛的人口比例分别为. 41、. 32、. 14 和. 12。[【10】](11.html#_ftn10)然后我们可以使用`chisq.test()`中的`p`属性将这些值组合成一个概率值向量，看看是否有显著差异。

```r
          # CHI-SQUARED GOODNESS-OF-FIT 2
          # OPTION: SPECIFY FREQUENCIES
          chi2 <- chisq.test(eyes, p = c(.41, .32, .15, .12))
          chi2  # Check results
                  Chi-squared test for given probabilities
          data:  eyes
          X-squared = 6.4717, df = 3, p-value = 0.09079

```

在这种情况下，我们的卡方值——同样，打印输出中的 X 平方——要小得多:6.4717。有了三个自由度，概率值为. 09079，不超过 0.5 的标准临界值。因此，我们可以得出结论，我们样本的眼睛颜色比例确实*而非*与普通人群的眼睛颜色比例有显著差异。

最后，我们应该清除工作空间中不需要的变量、对象或包:

```r
          # CLEAN UP
          detach("package:datasets", unload = TRUE)  # Unloads data sets package.
          rm(list = ls())  # Remove all objects from workspace.

```